{% extends "base.html" %}

{% block title %}AI Voice Assistant - Nyay Mitra{% endblock %}

{% block extra_css %}
<style>
    .assistant-container {
        max-width: 1000px;
        margin: 0 auto;
    }
    
    .page-header {
        text-align: center;
        margin-bottom: 30px;
    }
    
    .page-header h2 {
        color: #1a202c;
        margin-bottom: 10px;
        font-size: 32px;
        font-weight: 700;
    }
    
    .page-header p {
        color: #4a5568;
        font-size: 16px;
    }
    
    .settings-panel {
        background: rgba(248, 249, 250, 0.8);
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 30px;
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 20px;
        border: 1px solid rgba(226, 232, 240, 0.8);
    }
    
    .chat-area {
        background: rgba(248, 249, 250, 0.8);
        border-radius: 10px;
        padding: 20px;
        min-height: 400px;
        max-height: 500px;
        overflow-y: auto;
        margin-bottom: 20px;
        border: 1px solid rgba(226, 232, 240, 0.8);
    }
    
    .message {
        margin-bottom: 15px;
        padding: 12px 16px;
        border-radius: 8px;
        max-width: 80%;
    }
    
    .user-message {
        background: linear-gradient(135deg, #4a5568 0%, #2d3748 100%);
        color: white;
        margin-left: auto;
        text-align: right;
    }
    
    .assistant-message {
        background: white;
        color: #2d3748;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    .audio-player {
        margin-top: 10px;
        width: 100%;
    }
    
    .controls-panel {
        display: flex;
        gap: 10px;
        margin-bottom: 20px;
        flex-wrap: wrap;
    }
    
    .controls-panel button {
        flex: 1;
        min-width: 120px;
    }
    
    .controls-panel textarea {
        flex: 2;
        min-width: 300px;
    }
    
    .file-upload-section {
        background: rgba(248, 249, 250, 0.8);
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
        border: 1px solid rgba(226, 232, 240, 0.8);
    }
    
    .file-upload-section h3 {
        color: #1a202c;
        margin-bottom: 15px;
        font-size: 20px;
        font-weight: 600;
    }
    
    .recording {
        animation: pulse 1.5s infinite;
        background: linear-gradient(135deg, #f56565 0%, #c53030 100%) !important;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
</style>
{% endblock %}

{% block content %}
<div class="assistant-container">
    <div class="page-header">
        <h2>üé§ AI Voice Assistant</h2>
        <p>Interact with voice or text for legal assistance</p>
    </div>
    
    <div class="settings-panel">
        <div class="form-group">
            <label for="model">AI Model</label>
            <select id="model">
                <option value="llama-3.1-8b-instant">Llama 3.1 8B (Fast)</option>
                <option value="llama-3.1-70b-versatile">Llama 3.1 70B (Smart)</option>
                <option value="gemma-7b-it">Gemma 7B</option>
                <option value="llama-3-8b-8192">Llama 3 8B</option>
                <option value="llama-3-70b-8192">Llama 3 70B</option>
            </select>
        </div>
        
        <div class="form-group">
            <label for="complexity">Complexity Level</label>
            <select id="complexity">
                <option value="basic">Basic</option>
                <option value="intermediate" selected>Intermediate</option>
                <option value="complex">Complex</option>
            </select>
        </div>
    </div>
    
    <div class="chat-area" id="chatArea">
        <div style="text-align: center; color: #718096; padding: 50px 20px;">
            <span style="font-size: 48px;">üé§</span>
            <p>Start a conversation by speaking or typing your legal question</p>
        </div>
    </div>
    
    <div class="controls-panel">
        <button id="speakBtn" class="btn">üé§ Speak</button>
        <button id="stopBtn" class="btn btn-secondary" disabled>‚èπÔ∏è Stop</button>
        <textarea id="textInput" placeholder="Or type your question here..." rows="2"></textarea>
        <button id="sendTextBtn" class="btn">Send</button>
    </div>
    
    <div class="file-upload-section">
        <h3>üìé Upload Document for Analysis</h3>
        <div class="form-group">
            <input type="file" id="fileInput" accept=".pdf,.docx,.doc,.txt,.png,.jpg,.jpeg">
        </div>
        <button id="uploadBtn" class="btn">Analyze Document</button>
    </div>
</div>
{% endblock %}

{% block extra_js %}
<script>
    let audioElement = null;
    let recognition = null;
    
    // Initialize speech recognition
    if ('webkitSpeechRecognition' in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';
        
        recognition.onstart = () => {
            showLoading('Listening...', 'Speak now to ask your legal question');
        };
        
        recognition.onresult = async (event) => {
            hideLoading();
            const transcript = event.results[0][0].transcript;
            document.getElementById('textInput').value = transcript;
            await sendMessage(transcript);
        };
        
        recognition.onend = () => {
            hideLoading();
            document.getElementById('speakBtn').disabled = false;
            document.getElementById('speakBtn').classList.remove('recording');
        };
        
        recognition.onerror = (event) => {
            hideLoading();
            console.error('Speech recognition error:', event.error);
            alert('Error with speech recognition: ' + event.error);
        };
    }
    
    document.getElementById('speakBtn').addEventListener('click', () => {
        if (recognition) {
            recognition.start();
            document.getElementById('speakBtn').disabled = true;
            document.getElementById('speakBtn').classList.add('recording');
        } else {
            alert('Speech recognition not supported in this browser');
        }
    });
    
    document.getElementById('stopBtn').addEventListener('click', () => {
        if (audioElement) {
            audioElement.pause();
            audioElement.currentTime = 0;
            document.getElementById('stopBtn').disabled = true;
        }
    });
    
    document.getElementById('sendTextBtn').addEventListener('click', async () => {
        const text = document.getElementById('textInput').value.trim();
        if (text) {
            await sendMessage(text);
            document.getElementById('textInput').value = '';
        }
    });
    
    document.getElementById('uploadBtn').addEventListener('click', async () => {
        const fileInput = document.getElementById('fileInput');
        const file = fileInput.files[0];
        
        if (!file) {
            alert('Please select a file');
            return;
        }
        
        const formData = new FormData();
        formData.append('file', file);
        formData.append('model', document.getElementById('model').value);
        formData.append('type', 'document');
        
        addMessage('user', `Analyzing document: ${file.name}...`);
        showLoading('Analyzing Document...', 'Extracting text and generating legal insights');
        
        try {
            const response = await fetch('/process-voice-file', {
                method: 'POST',
                body: formData
            });
            
            const data = await response.json();
            hideLoading();
            
            if (data.success) {
                addMessage('assistant', data.text, data.audio_url);
            } else {
                addMessage('assistant', 'Error: ' + data.error);
            }
        } catch (error) {
            hideLoading();
            addMessage('assistant', 'Error analyzing document: ' + error.message);
        }
        
        fileInput.value = '';
    });
    
    async function sendMessage(text) {
        addMessage('user', text);
        
        const model = document.getElementById('model').value;
        const complexity = document.getElementById('complexity').value;
        
        showLoading('AI is Processing...', 'Generating voice response with legal analysis');
        
        try {
            const response = await fetch('/voice-chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({ text, model, complexity })
            });
            
            const data = await response.json();
            hideLoading();
            
            if (data.success) {
                addMessage('assistant', data.text, data.audio_url);
            } else {
                addMessage('assistant', 'Error: ' + data.error);
            }
        } catch (error) {
            hideLoading();
            addMessage('assistant', 'Error: ' + error.message);
        }
    }
    
    function addMessage(role, content, audioUrl = null) {
        const chatArea = document.getElementById('chatArea');
        
        // Remove empty state message
        if (chatArea.querySelector('[style*="text-align: center"]')) {
            chatArea.innerHTML = '';
        }
        
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${role}-message`;
        messageDiv.textContent = content;
        
        if (audioUrl) {
            const audio = document.createElement('audio');
            audio.controls = true;
            audio.className = 'audio-player';
            audio.src = audioUrl;
            audio.onplay = () => {
                audioElement = audio;
                document.getElementById('stopBtn').disabled = false;
            };
            audio.onended = () => {
                document.getElementById('stopBtn').disabled = true;
            };
            messageDiv.appendChild(audio);
            
            // Auto-play assistant responses
            if (role === 'assistant') {
                setTimeout(() => audio.play(), 100);
            }
        }
        
        chatArea.appendChild(messageDiv);
        chatArea.scrollTop = chatArea.scrollHeight;
    }
</script>
{% endblock %}